{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trustworthy AI for Open RAN: Demo Notebook\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading a trained model\n",
    "2. Running inference with uncertainty quantification\n",
    "3. Interpreting decisions with SHAP\n",
    "4. Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.environment.ran_env import RANEnvironment\n",
    "from src.models.baseline import BaselinePolicy\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RANEnvironment(\n",
    "    n_cells=10,\n",
    "    n_ues_per_cell=15,\n",
    "    traffic_pattern='commute',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Observation space: {env.observation_space.shape}\")\n",
    "print(f\"Action space: {env.action_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint (placeholder)\n",
    "policy = BaselinePolicy(n_cells=10)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "total_reward = 0\n",
    "metrics = []\n",
    "\n",
    "for step in range(100):\n",
    "    action = policy.predict(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    total_reward += reward\n",
    "    metrics.append(info)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"Total reward: {total_reward:.2f}\")\n",
    "print(f\"Average throughput: {np.mean([m['total_throughput'] for m in metrics]):.2f} Mbps\")\n",
    "print(f\"SLA violation rate: {np.mean([m['sla_violation_rate'] for m in metrics]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Throughput over time\n",
    "axes[0, 0].plot([m['total_throughput'] for m in metrics])\n",
    "axes[0, 0].set_title('Throughput Over Time')\n",
    "axes[0, 0].set_xlabel('Time Step')\n",
    "axes[0, 0].set_ylabel('Throughput (Mbps)')\n",
    "\n",
    "# SLA violations\n",
    "axes[0, 1].plot([m['sla_violations'] for m in metrics], color='red')\n",
    "axes[0, 1].set_title('SLA Violations')\n",
    "axes[0, 1].set_xlabel('Time Step')\n",
    "axes[0, 1].set_ylabel('Number of Violations')\n",
    "\n",
    "# Fairness (Jain's index)\n",
    "axes[1, 0].plot([m['jain_index'] for m in metrics], color='green')\n",
    "axes[1, 0].axhline(y=0.85, color='r', linestyle='--', label='Target')\n",
    "axes[1, 0].set_title(\"Jain's Fairness Index\")\n",
    "axes[1, 0].set_xlabel('Time Step')\n",
    "axes[1, 0].set_ylabel('Jain Index')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Energy consumption\n",
    "axes[1, 1].plot([m['energy'] for m in metrics], color='orange')\n",
    "axes[1, 1].set_title('Energy Consumption')\n",
    "axes[1, 1].set_xlabel('Time Step')\n",
    "axes[1, 1].set_ylabel('Normalized Energy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/demo_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Uncertainty Quantification (Placeholder)\n",
    "\n",
    "In the full implementation, this section would:\n",
    "- Run ensemble inference\n",
    "- Show uncertainty estimates\n",
    "- Plot reliability diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpretability with SHAP (Placeholder)\n",
    "\n",
    "In the full implementation, this section would:\n",
    "- Compute SHAP values\n",
    "- Show feature importance\n",
    "- Visualize attention weights for GNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
